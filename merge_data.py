# merge_data.py
# Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø®ÙˆØ§Ù†Ø¯Ù‡ Ùˆ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø§Ø¯ØºØ§Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
# Ù†ÛŒØ§Ø²Ù…Ù†Ø¯: pip install pandas

import pandas as pd
import json
import re

# --- Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ ---
USNEWS_FILE = "usnews_university_data.csv"
DEADLINES_FILE = "successful_deadlines.csv"
PROFESSORS_FILE = "all_professors.csv"
OUTPUT_FILE = "final_university_database.csv"

def normalize_name(name):
    """
    Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ù‡ØªØ±ØŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    - Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
    - ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©
    - Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ
    """
    if pd.isna(name):
        return ""
    name = name.lower().strip()
    name = re.sub(r'[^a-z0-9\s-]', '', name)
    name = re.sub(r'\s+', ' ', name)
    return name

def main():
    print("--- Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---")

    # --- Û±. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ ---
    try:
        print(f" Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§: {USNEWS_FILE}")
        df_usnews = pd.read_csv(USNEWS_FILE)
        
        print(f" Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø¯Ø¯Ù„Ø§ÛŒÙ†â€ŒÙ‡Ø§: {DEADLINES_FILE}")
        df_deadlines = pd.read_csv(DEADLINES_FILE)
        
        print(f" Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§Ø³Ø§ØªÛŒØ¯: {PROFESSORS_FILE}")
        df_professors = pd.read_csv(PROFESSORS_FILE)
        print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯Ù†Ø¯.")
    except FileNotFoundError as e:
        print(f"âŒ Ø®Ø·Ø§: ÙØ§ÛŒÙ„ {e.filename} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ØªÙ…Ø§Ù… Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯.")
        return

    # --- Û². Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³Ø§ØªÛŒØ¯ ---
    print("\n Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³Ø§ØªÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡...")
    # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù… Ø§Ø³ØªØ§Ø¯
    df_professors.dropna(subset=['name'], inplace=True)
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡Ø± Ø§Ø³ØªØ§Ø¯ Ø¨Ù‡ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ùˆ Ø³Ù¾Ø³ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡
    professors_grouped = (
        df_professors.groupby('affiliation')
        .apply(lambda x: x.to_dict('records'))
        .reset_index(name='professors_list')
    )
    # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø±Ø´ØªÙ‡ JSON
    professors_grouped['professors'] = professors_grouped['professors_list'].apply(lambda x: json.dumps(x, indent=2))
    professors_grouped.drop(columns=['professors_list'], inplace=True)
    print(f"âœ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª {len(df_professors)} Ø§Ø³ØªØ§Ø¯ Ø¯Ø± {len(professors_grouped)} Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯.")

    # --- Û³. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø¨Ù‡ØªØ± ---
    print("\n Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚...")
    df_usnews['normalized_name'] = df_usnews['Name'].apply(normalize_name)
    df_deadlines['normalized_name'] = df_deadlines['University'].apply(normalize_name)
    professors_grouped['normalized_name'] = professors_grouped['affiliation'].apply(normalize_name)

    # --- Û´. Ø§Ø¯ØºØ§Ù… (Merge) Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---
    print(" Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ US News Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø¯Ù„Ø§ÛŒÙ†â€ŒÙ‡Ø§...")
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² left merge Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ØªÙ…Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ
    merged_df = pd.merge(
        df_usnews,
        df_deadlines,
        on='normalized_name',
        how='left'
    )

    print(" Ø§Ø¯ØºØ§Ù… Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³Ø§ØªÛŒØ¯...")
    final_df = pd.merge(
        merged_df,
        professors_grouped,
        on='normalized_name',
        how='left'
    )
    print("âœ… Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    # --- 5. ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ---
    print("\n ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")

    # Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
    final_df = final_df.rename(columns={
        'Name': 'university_name',
        'Website': 'university_website',
        'Rankings': 'rankings_data',
        'Data': 'university_data',
        'Found Deadline Info': 'deadline_info', # Ø§Ø² df_deadlines
        'Deadline Page URL': 'deadline_url',   # Ø§Ø² df_deadlines
        'affiliation': 'affiliation_prof',     # Ø§Ø² professors_grouped
    })

    # Ù„ÛŒØ³Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø¯Ù„Ø®ÙˆØ§Ù‡
    final_columns = [
        'university_name',
        'university_website',
        'university_data',
        'rankings_data',
        'deadline_info',
        'deadline_url',
        'professors'
    ]

    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ùˆ Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ
    for col in final_columns:
        if col not in final_df.columns:
            final_df[col] = pd.NA

    # Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ùˆ Ø­Ø°Ù Ø¨Ù‚ÛŒÙ‡ (Ø´Ø§Ù…Ù„ normalized_name Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ merge)
    final_df = final_df[final_columns].copy()

    # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± NaN Ø¨Ø§ Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨
    final_df['deadline_info'].fillna("Not Found", inplace=True)
    final_df['deadline_url'].fillna("N/A", inplace=True)
    final_df['professors'].fillna("[]", inplace=True) # Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ JSON Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ§Ø¯

    # --- Û¶. Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ---
    final_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
    print("\nğŸ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
    print(f"   ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± '{OUTPUT_FILE}' Ø¨Ø§ {len(final_df)} Ø±Ø¯ÛŒÙ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")


if __name__ == "__main__":
    main()
